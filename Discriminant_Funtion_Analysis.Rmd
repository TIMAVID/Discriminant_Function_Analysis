---
title: "Discriminant_Function_Analysis"
author: "David Ledesma and Hans Bilger"
date: "4/25/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# What is a discriminant function anaysis (DFA) used for?

> A DFA can be used to predict group membership based on discriminating continous variable. It can also give a sense of how well those groups can be differentiated by those variables.

<img src = "img/Screen Shot 2019-05-01 at 4.36.17 PM.png" />

> In essence, a DFA is the reverse of a multivariate analysis of variance or MANOVA. In a MANOVA, the groups are the independent variables and the predictors are the dependent variables. For a DFA, the groups are the dependent variables while the predictors are the independent variables. 

# Assumptions and limitations

* 1) Unequal sample sizes are not a problem; however, the sample size within groups must be greater than the number of independent variable predictors (Rule of thumb: ~ 4 to 5 as many observations as predictor variables).

* 2) Outliers can cause problems when assesing significance and should transformed or removed. Normally distributed variables are prefered, but variables not normally distributed will not influence the significance tests as long as the non-normality is not due to outliers.

* 3) It is important that the independent variables must not be correlated with one another and have low multicollinearity. 

* 4) It is important to evaluate that there is not significant heterogeneity in the variance and co-variance matricies between groups. 

> Discriminant function anaysis is similar to logistic regression and in fact both can be used to answer the same research questions. In many cases logistic regression may be preferable to a discriminant function anaysis because it has less assumptions and restrictions. However, a discriminant function anaysis may be prefered when looking at many different classifications. 

# How does a discriminant function anaysis work?

> The analysis creates linear combinations of predictors, so called discriminant functions. The number of functions is equal to one less than the number of groups or equal to the number of predictors, whichever is smaller. Each discriminant function maximizes the amount of discrimination between groups while also remaining non-correlated with the other discriminant functions.

# Linear discriminant analysis

```{r}
library(MASS) # required for the lda() function
library(tidyverse)


# Load the data
data("iris") # biult in R dataset

# Split the data into training (80%) and test set (20%)
# What is training vs. test data
library(caret) 
set.seed(123) # set random numbers to be the same for reproducable simulations
training.samples <- iris$Species %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- iris[training.samples, ]
test.data <- iris[-training.samples, ]

```


> One way to nomalize your data
```{r}
# Estimate preprocessing parameters

preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# scale divides each value by the SD of the attribute(variable)
# center calculates mean for each attribute and subtracts from each value

# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
```


```{r}
# Loading in data from separate files
# 
# learning_dat <- read.csv("YourLearningData.csv") # read in the data you will use to teach the analysis what each category looks like - minimally, you need a column for category (in your case, individual) plus one column for each of your variables
# 
# experimental_dat <- read.csv("YourExperimentalData.csv") # read in the data for which you will be predicting categories - this should be formatted exactly like your learing data
```


```{r}
# Model creation
LDA_object <- lda(Species~., data = train.transformed) # creates an object that is the results of the learning phase of the LDA - this is what you will use to predict what category each subsequent set of variables you feed it most likely belong to
LDA_object
# Prior probabilities of groups = probability of selecting one observation and it belonging to that respective group
# Group means = means for each variable belonging to a group
# Coefficients of linear discriminants = Coefficients of each discriminant creating the discriminant function
# Proportions of trace = proportion of variance between groups as explained by each discriminant function 

plot(LDA_object, col = as.integer(train.transformed$Species)) # vizualize separation of groups by discriminant functions 

plot(LDA_object, dimen = 1, type = "b") # visualize only separation by LD1 
```

```{r}
# Model predictions
Predict_results <- predict(LDA_object, newdata = test.transformed) # use the LDA results object to predict the category for your experimental data 
```

```{r}
# Plotting result in ggplot
lda.data <- cbind(train.transformed, predict(LDA_object)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = Species))
```

```{r}
# Model accuracy

mean(Predict_results$class==test.transformed$Species)
```

# Quadratic discriminant analysis

> Quadratic discriminant analysis is an alternative to linear discriminant analysis. This type of discriminant analysis does not assume equal variance and co-variance matricies between groups. This makes this type of analysis better for very large datasets.  

```{r}

# Produce model
QDAmodel <- qda(Species~., data = train.transformed)
QDAmodel

# How well does the model fit the training data?
qda.train <- predict(QDAmodel) # generate 
train.transformed$qda <- qda.train$class
table(train.transformed$qda, train.transformed$Species)
mean(qda.train$class == train.transformed$class)

# Make predictions
predictions <- predict(QDAmodel, newdata = test.transformed)
test.transformed$qda <- predictions$class

# Model accuracy
table(test.transformed$qda, test.transformed$Species)
mean(predictions$class == test.transformed$Species)
```


```{r}
#  plot the quadratic discriminant functions for each variable combination
library(klaR)
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train.transformed, method="qda")
```


