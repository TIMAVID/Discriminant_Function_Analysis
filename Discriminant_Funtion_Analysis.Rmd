---
title: "Discriminant Function Analysis"
author: "David Ledesma and Hans Bilger"
date: "May 2, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# What is a discriminant function anaysis (DFA) used for?

> A DFA can be used to predict group membership based on discriminating continous variables. It can also give a sense of how well those groups can be differentiated by those variables.

<img src = "img/Screen Shot 2019-05-01 at 4.36.17 PM.png" />

> In essence, a DFA is the reverse of a multivariate analysis of variance or MANOVA. In a MANOVA, the groups are the independent variables and the predictors are the dependent variables. For a DFA, the groups are the dependent variables while the predictors are the independent variables. 

# Assumptions and limitations

* 1) Unequal sample sizes are not a problem; however, the sample size within groups must be greater than the number of independent variable predictors (Rule of thumb: ~ 4 to 5 as many observations as predictor variables).

* 2) Outliers can cause problems when assessing significance and should transformed or removed. Normally distributed variables are preferred, but non-normally distributed variables will not influence model significance as long as the non-normality isn't driven by outliers.

* 3) Independent variables must uncorrelated and have low multicollinearity. 

* 4) There shouldn't be significant heterogeneity in the variance and co-variance matricies between groups. 

> Discriminant function anaysis is similar to logistic regression. (In fact, both can be used to answer the same research questions.) In many cases, logistic regression may be preferable to a discriminant function anaysis because it has fewer assumptions and restrictions. However, a discriminant function anaysis may be prefered when the dependent variable contains more than two groups.

# How does a discriminant function anaysis work?

> The analysis creates "discriminant functions" using linear combinations of predictor variables. The number of functions is equal to either one less than the number of groups or the number of predictorsâ€”whichever is smaller. Each discriminant function maximizes the amount of discrimination between groups while also remaining non-correlated with the other discriminant functions. The model made from these discriminant functions can then be used to predict group membership on a new, uncharacterized sample.

# Linear discriminant analysis

```{r}
library(MASS) # required for the lda() function
library(tidyverse)

# Load the data
data("iris") # built-in R dataset
```

![Alt text](img/Fig1.jpg)
![Alt text](img/Screen Shot 2019-05-02 at 10.50.11 AM.png)

> Split the data into training (80%) and test (20%) sets

```{r}
library(caret) 
# set random numbers to be the same for reproducable simulations
set.seed(123) 
# conduct a stratified, random split of your sample
training.samples <- iris$Species %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- iris[training.samples, ]
test.data <- iris[-training.samples, ]
```

> One way to nomalize your data

```{r}
# Estimate preprocessing parameters

preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
  
# "scale" divides each value by the SD of the attribute(variable)
# "center" calculates mean for each attribute and subtracts from each value

# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
```

> In case you'd prefer to load in training and test data from separate files:

```{r}
# Loading in data from separate files

# training_dat <- read.csv("YourLearningData.csv")

# test_dat <- read.csv("YourExperimentalData.csv") 

# Your training and test data must be formatted exactly the same.
```

> Create your model:

```{r}
# Model creation
LDA_object <- lda(Species~., data = train.transformed) # creates an object that is the results of the learning phase of the LDA - this is what you will use to predict what category each subsequent set of variables you feed it most likely belong to
LDA_object
# Prior probabilities of groups = probability of selecting one observation and it belonging to that respective group
# Group means = means for each variable belonging to a group
# Coefficients of linear discriminants = Coefficients of each discriminant creating the discriminant function
# Proportions of trace = proportion of variance between groups as explained by each discriminant function 

plot(LDA_object, col = as.integer(train.transformed$Species)) # vizualize separation of groups by discriminant functions 

plot(LDA_object, dimen = 1, type = "b") # visualize only separation by LD1 
```

> Now, use your model to predict group membership of your training dataset.

```{r}
Predict_results <- predict(LDA_object, newdata = test.transformed) # use the LDA results object to predict the category for your experimental data 
```

```{r}
# Plotting the result in ggplot
lda.data <- cbind(train.transformed, predict(LDA_object)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = Species))
```

> Now, test the accuracy of your model by calculating the fraction of correct classifications.

```{r}
mean(Predict_results$class==test.transformed$Species)
```

# Quadratic discriminant analysis

> Quadratic discriminant analysis is an alternative to linear discriminant analysis. This type of discriminant analysis does not assume equal variance and co-variance matricies between groups. This makes this type of analysis better for very large datasets.  

```{r}

# Produce model
QDAmodel <- qda(Species~., data = train.transformed)
QDAmodel

# How well does the model fit the training data?
qda.train <- predict(QDAmodel) # generate 
train.transformed$qda <- qda.train$class
table(train.transformed$qda, train.transformed$Species)
mean(qda.train$class == train.transformed$class)

# Make predictions
predictions <- predict(QDAmodel, newdata = test.transformed)
test.transformed$qda <- predictions$class

# Model accuracy
table(test.transformed$qda, test.transformed$Species)
mean(predictions$class == test.transformed$Species)
```


```{r}
#  plot the quadratic discriminant functions for each variable combination
library(klaR)
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train.transformed, method="qda")
```


