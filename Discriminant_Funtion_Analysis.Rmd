---
title: "Discriminant_Function_Analysis"
author: "David Ledesma and Hans Bilger"
date: "4/25/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# What is a discriminant function anaysis (DFA) used for?

### A DFA can be used to predict group membership based on discriminating continous variable. It can also give a sense of how well those groups can be differentiated by those variables.

### In essence, a DFA is the reverse of a multivariate analysis of variance or MANOVA. In a MANOVA, the groups are the independent variables and the predictors are the dependent variables. For a DFA, the groups are the dependent variables while the predictors are the independent variables. 

# Assumptions and limitations

### 1) Unequal sample sizes are not a problem; however, the sample size within groups must be greater than the number of independent variable predictors (Rule of thumb: ~ 4 to 5 as many observations as predictor variables).

### 2) Outliers can cause problems when assesing significance and should transformed or removed. Normally distributed variables are prefered, but variables not normally distributed will not influence the significance tests as long as the non-normality is not due to outliers.

### 3) It is important that the independent variables must not be correlated with one another and have low multicollinearity. 

### 4) It is important to evaluate that there is not significant heterogeneity in the variance and co-variance matricies within groups. 

### Discriminant function anaysis is similar to logistic regression and in fact both can be used to answer the same research questions. In many cases logistic regression may be preferable to a discriminant function anaysis because it has less assumptions and restrictions. However, a discriminant function anaysis may be prefered when looking at many different classifications. 

# How does a discriminant function anaysis work?

### The analysis creates linear combinations of predictors, so called discriminant functions. The number of functions is equal to one less than the number of groups or equal to the number of predictors, whichever is smaller. Each discriminant function maximizes the amount of discrimination between groups while also remaining non-correlated with the other discriminant functions.

# Linear discriminant analysis

```{r}
library(MASS) # required for the lda() function
library(tidyverse)

# Load the data
data("iris")

# Split the data into training (80%) and test set (20%)
library(caret) 
set.seed(123) # set random numbers to be the same for reproducable simulations
training.samples <- iris$Species %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- iris[training.samples, ]
test.data <- iris[-training.samples, ]

```

```{r}
# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
```


```{r}
# Loading in data from separate files
# 
# learning_dat <- read.csv("YourLearningData.csv") # read in the data you will use to teach the analysis what each category looks like - minimally, you need a column for category (in your case, individual) plus one column for each of your variables
# 
# experimental_dat <- read.csv("YourExperimentalData.csv") # read in the data for which you will be predicting categories - this should be formatted exactly like your learing data
# 
# 
# 
# Predict_results <- predict(LDA_object, newdata = experimental_dat) # use the LDA results object to predict the category for your experimental data - NOTE: if you have multiple rows in your experimental data, you'll need to use a for loop to compare each row to your LDA object
```


```{r}
LDA_object <- lda(Species~., data = train.transformed) # creates an object that is the results of the learning phase of the LDA - this is what you will use to predict what category each subsequent set of variables you feed it most likely belong to
LDA_object
plot(LDA_object, col = as.integer(train.transformed$Species))
```

```{r}
Predict_results <- predict(LDA_object, newdata = test.transformed) # use the LDA results object to predict the category for your experimental data - NOTE: if you have multiple rows in your experimental data, you'll need to use a for loop to compare each row to your LDA object - try this on your own first and if you can't make it work, I'll show you what I did
```

```{r}
lda.data <- cbind(train.transformed, predict(LDA_object)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = Species))
```

```{r}
# Model accuracy

mean(Predict_results$class==test.transformed$Species)
```

# Quadratic discriminant analysis








